{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XumW1PvfB-36"
      },
      "outputs": [],
      "source": [
        "# pip install yt-dlp\n",
        "# pip install youtube-transcript-api\n",
        "# pip install textwrap3\n",
        "# run on jupyter notebook\n",
        "import subprocess #lets us download captions\n",
        "import os\n",
        "import re # Detect lines that are just numbers and skip them\n",
        "import glob #let's python search for files matching a pattern\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPiO_cZzCCqg"
      },
      "outputs": [],
      "source": [
        "video_url = \"https://www.youtube.com/watch?v=wq2jG_Ww_xc\"\n",
        "# def url_spliter(video_url):\n",
        "#   id1 = video_url.split(\"/watch?v=\")[-1]\n",
        "#   id2 = id1.split(\"&\")\n",
        "#   id3 = id2[0]\n",
        "#   return id3\n",
        "\n",
        "#One way to get video URL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6JvLLfmVCk9r"
      },
      "outputs": [],
      "source": [
        "import subprocess #lets us download captions\n",
        "import os\n",
        "import re # Detect lines that are just numbers and skip them\n",
        "import glob #let's python search for files matching a pattern\n",
        "\n",
        "def get_transcript(video_url: str, lang = \"en\") -> str:\n",
        "  existing_vtts = set(glob.glob(\"*.vtt\")) # Stores videos in a set to see which video was downloaded\n",
        "\n",
        "  # First, get information about available captions\n",
        "  info_result = subprocess.run([\n",
        "      \"yt-dlp\",\n",
        "      \"--list-subs\",\n",
        "      video_url\n",
        "  ], check=False, text=True, capture_output=True)\n",
        "\n",
        "  print(\"Available captions:\")\n",
        "  print(info_result.stdout)\n",
        "  print(info_result.stderr)\n",
        "\n",
        "\n",
        "  result = subprocess.run([\n",
        "  \"yt-dlp\", #download captions\n",
        "   \"--write-auto-sub\", #auto subtitles if possible\n",
        "  \"--write-sub\", #Also can use creator captions if they have it\n",
        "  \"--sub-langs\", f\"{lang}\", #english language\n",
        "  \"--skip-download\", #prevents actual video from being downloaded\n",
        "  \"--output\", \"%(id)s.%(ext)s\", #forces file names to be VIDEOID.ext\n",
        "  \"--verbose\", # Add verbose flag for debugging\n",
        "  video_url #enter actual link\n",
        "  ], check = False, text = True, capture_output = True)\n",
        "\n",
        "\n",
        "# This creates a new folder that's not in the existing_vtt with the captions\n",
        "\n",
        "# new_vtts is a list. glob.glob searches files that has the vtt ending.\n",
        "# For every file with the ending, if it's not in our existing_vtt, then we know\n",
        "# it has to be a caption file, so we put it in new_vtt.\n",
        "  new_vtts = [f for f in glob.glob(\"*.vtt\") if f not in existing_vtts]\n",
        "\n",
        "# If the caption file doesn't work and nothing is new, raise error\n",
        "  if not new_vtts:\n",
        "    print(\"No creator captions, trying auto captions\")\n",
        "    other_result = subprocess.run([\n",
        "    \"yt-dlp\", #download captions\n",
        "    \"--write-auto-sub\", #auto subtitles if possible\n",
        "    \"--write-sub\", #Also can use creator captions if they have it\n",
        "    \"--sub-langs\", f\"{lang}\", #english language\n",
        "    \"--skip-download\", #prevents actual video from being downloaded\n",
        "    \"--output\", \"%(id)s.%(ext)s\", #forces file names to be VIDEOID.ext\n",
        "    \"--verbose\", # Add verbose flag for debugging\n",
        "    video_url #enter actual link\n",
        "    ], check = False, text = True, capture_output = True)\n",
        "\n",
        "  new_vtts = [f for f in glob.glob(\"*.vtt\") if f not in existing_vtts]\n",
        "\n",
        "  if not new_vtts:\n",
        "    raise FileNotFoundError(\"Caption file not found. Maybe captions aren't available for this video.\")\n",
        "\n",
        "# Get rid of empty spaces and arrows\n",
        "  vtt_file = new_vtts[0]\n",
        "  print(f\"Using caption file {vtt_file}\")\n",
        "  transcript = \"\"\n",
        "  with open(vtt_file, \"r\", encoding = \"utf-8\") as f:\n",
        "    for line in f:\n",
        "      line = line.strip()\n",
        "      if not line:\n",
        "        continue\n",
        "      if \"-->\" in line:\n",
        "        continue\n",
        "      if re.match(r\"^\\d+$\", line):\n",
        "        continue\n",
        "      transcript += line + \" \"\n",
        "    cleaned_transcript = re.sub(r\"<.*?>\", \" \", transcript)\n",
        "  return cleaned_transcript.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "3RX4ilwdVJts",
        "outputId": "5d8f13b6-bcf9-451a-8a54-928bfd492b13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available captions:\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=wq2jG_Ww_xc\n",
            "[youtube] wq2jG_Ww_xc: Downloading webpage\n",
            "[youtube] wq2jG_Ww_xc: Downloading tv client config\n",
            "[youtube] wq2jG_Ww_xc: Downloading tv player API JSON\n",
            "[youtube] wq2jG_Ww_xc: Downloading tv simply player API JSON\n",
            "[youtube] wq2jG_Ww_xc: Downloading player 475ca5fd-main\n",
            "[info] Available automatic captions for wq2jG_Ww_xc:\n",
            "Language Name                  Formats\n",
            "ab       Abkhazian             vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "aa       Afar                  vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "af       Afrikaans             vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ak       Akan                  vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "sq       Albanian              vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "am       Amharic               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ar       Arabic                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "hy       Armenian              vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "as       Assamese              vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ay       Aymara                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "az       Azerbaijani           vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "bn       Bangla                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ba       Bashkir               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "eu       Basque                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "be       Belarusian            vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "bho      Bhojpuri              vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "bs       Bosnian               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "br       Breton                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "bg       Bulgarian             vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "my       Burmese               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ca       Catalan               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ceb      Cebuano               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "zh-Hans  Chinese (Simplified)  vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "zh-Hant  Chinese (Traditional) vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "co       Corsican              vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "hr       Croatian              vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "cs       Czech                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "da       Danish                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "dv       Divehi                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "nl       Dutch                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "dz       Dzongkha              vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "en-orig  English (Original)    vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "en       English               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "eo       Esperanto             vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "et       Estonian              vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ee       Ewe                   vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "fo       Faroese               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "fj       Fijian                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "fil      Filipino              vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "fi       Finnish               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "fr       French                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "gaa      Ga                    vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "gl       Galician              vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "lg       Ganda                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ka       Georgian              vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "de       German                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "el       Greek                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "gn       Guarani               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "gu       Gujarati              vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ht       Haitian Creole        vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ha       Hausa                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "haw      Hawaiian              vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "iw       Hebrew                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "hi       Hindi                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "hmn      Hmong                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "hu       Hungarian             vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "is       Icelandic             vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ig       Igbo                  vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "id       Indonesian            vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "iu       Inuktitut             vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ga       Irish                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "it       Italian               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ja       Japanese              vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "jv       Javanese              vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "kl       Kalaallisut           vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "kn       Kannada               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "kk       Kazakh                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "kha      Khasi                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "km       Khmer                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "rw       Kinyarwanda           vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ko       Korean                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "kri      Krio                  vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ku       Kurdish               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ky       Kyrgyz                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "lo       Lao                   vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "la       Latin                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "lv       Latvian               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ln       Lingala               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "lt       Lithuanian            vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "lua      Luba-Lulua            vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "luo      Luo                   vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "lb       Luxembourgish         vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "mk       Macedonian            vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "mg       Malagasy              vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ms       Malay                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ml       Malayalam             vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "mt       Maltese               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "gv       Manx                  vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "mi       MÄori                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "mr       Marathi               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "mn       Mongolian             vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "mfe      Morisyen              vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ne       Nepali                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "new      Newari                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "nso      Northern Sotho        vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "no       Norwegian             vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ny       Nyanja                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "oc       Occitan               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "or       Odia                  vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "om       Oromo                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "os       Ossetic               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "pam      Pampanga              vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ps       Pashto                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "fa       Persian               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "pl       Polish                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "pt       Portuguese            vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "pt-PT    Portuguese (Portugal) vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "pa       Punjabi               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "qu       Quechua               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ro       Romanian              vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "rn       Rundi                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ru       Russian               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "sm       Samoan                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "sg       Sango                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "sa       Sanskrit              vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "gd       Scottish Gaelic       vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "sr       Serbian               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "crs      Seselwa Creole French vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "sn       Shona                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "sd       Sindhi                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "si       Sinhala               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "sk       Slovak                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "sl       Slovenian             vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "so       Somali                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "st       Southern Sotho        vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "es       Spanish               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "su       Sundanese             vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "sw       Swahili               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ss       Swati                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "sv       Swedish               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "tg       Tajik                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ta       Tamil                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "tt       Tatar                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "te       Telugu                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "th       Thai                  vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "bo       Tibetan               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ti       Tigrinya              vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "to       Tongan                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ts       Tsonga                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "tn       Tswana                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "tum      Tumbuka               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "tr       Turkish               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "tk       Turkmen               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "uk       Ukrainian             vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ur       Urdu                  vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ug       Uyghur                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "uz       Uzbek                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "ve       Venda                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "vi       Vietnamese            vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "war      Waray                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "cy       Welsh                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "fy       Western Frisian       vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "wo       Wolof                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "xh       Xhosa                 vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "yi       Yiddish               vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "yo       Yoruba                vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "zu       Zulu                  vtt, srt, ttml, srv3, srv2, srv1, json3\n",
            "wq2jG_Ww_xc has no subtitles\n",
            "\n",
            "WARNING: [youtube] Falling back to generic n function search\n",
            "         player = https://www.youtube.com/s/player/475ca5fd/player_ias.vflset/en_US/base.js\n",
            "WARNING: [youtube] wq2jG_Ww_xc: nsig extraction failed: Some formats may be missing\n",
            "         n = BzWkpp2W_RL3nOI ; player = https://www.youtube.com/s/player/475ca5fd/player_ias.vflset/en_US/base.js\n",
            "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] wq2jG_Ww_xc: nsig extraction failed: Some formats may be missing\n",
            "         n = -lUS6VXExmgWb_W ; player = https://www.youtube.com/s/player/475ca5fd/player_ias.vflset/en_US/base.js\n",
            "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] wq2jG_Ww_xc: nsig extraction failed: Some formats may be missing\n",
            "         n = eseBBykMD8jcbzA ; player = https://www.youtube.com/s/player/475ca5fd/player_ias.vflset/en_US/base.js\n",
            "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] wq2jG_Ww_xc: nsig extraction failed: Some formats may be missing\n",
            "         n = GRyR8VAPQlsTg2S ; player = https://www.youtube.com/s/player/475ca5fd/player_ias.vflset/en_US/base.js\n",
            "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] wq2jG_Ww_xc: nsig extraction failed: Some formats may be missing\n",
            "         n = 8_uN-pl24Iy6oQ7 ; player = https://www.youtube.com/s/player/475ca5fd/player_ias.vflset/en_US/base.js\n",
            "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] wq2jG_Ww_xc: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
            "WARNING: Only images are available for download. use --list-formats to see them\n",
            "\n",
            "No creator captions, trying auto captions\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "Caption file not found. Maybe captions aren't available for this video.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m text = \u001b[43mget_transcript\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(text[:\u001b[32m100\u001b[39m])\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mget_transcript\u001b[39m\u001b[34m(video_url, lang)\u001b[39m\n\u001b[32m     54\u001b[39m   new_vtts = [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m glob.glob(\u001b[33m\"\u001b[39m\u001b[33m*.vtt\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m existing_vtts]\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_vtts:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCaption file not found. Maybe captions aren\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt available for this video.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Get rid of empty spaces and arrows\u001b[39;00m\n\u001b[32m     60\u001b[39m   vtt_file = new_vtts[\u001b[32m0\u001b[39m]\n",
            "\u001b[31mFileNotFoundError\u001b[39m: Caption file not found. Maybe captions aren't available for this video."
          ]
        }
      ],
      "source": [
        "text = get_transcript(video_url)\n",
        "print(text[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5eGXZylbPzT",
        "outputId": "324924e3-fef6-4e59-ebde-ccce7bee3a0f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'text' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     59\u001b[39m             i += \u001b[32m1\u001b[39m\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(cleaned)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m long_text = remove_consecutive_duplicate_phrases(\u001b[43mtext\u001b[49m)  \u001b[38;5;66;03m# your video transcript\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Wrap text to 80 characters per line\u001b[39;00m\n\u001b[32m     66\u001b[39m joined_text = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n",
            "\u001b[31mNameError\u001b[39m: name 'text' is not defined"
          ]
        }
      ],
      "source": [
        "import textwrap\n",
        "from typing import List, Optional\n",
        "\n",
        "def _normalize_token(t: str) -> str:\n",
        "    # remove angle-tags, lower-case, strip surrounding punctuation\n",
        "    t = re.sub(r\"<.*?>\", \"\", t)\n",
        "    t = t.lower()\n",
        "    t = re.sub(r\"^[^\\w']+|[^\\w']+$\", \"\", t)  # strip leading/trailing punctuation (keep apostrophes)\n",
        "    return t\n",
        "\n",
        "def remove_consecutive_duplicate_phrases(words: List[str],\n",
        "                                        max_seq_len: Optional[int] = None,\n",
        "                                        normalize: bool = False) -> List[str]:\n",
        "    \"\"\"\n",
        "    Collapse consecutive duplicated phrases in a token list.\n",
        "      - words: list of word tokens (strings)\n",
        "      - max_seq_len: maximum phrase length to consider (None -> n//2)\n",
        "      - normalize: if True, compare using a normalized version of tokens (lowercase, strip tags/punct)\n",
        "    Returns a cleaned list of tokens with duplicates collapsed (one copy kept).\n",
        "    \"\"\"\n",
        "    n = len(words)\n",
        "    if n == 0:\n",
        "        return []\n",
        "\n",
        "    if max_seq_len is None:\n",
        "        max_seq_len = n // 2\n",
        "    max_seq_len = max(1, min(max_seq_len, n // 2))\n",
        "\n",
        "    # build normalized view for comparisons\n",
        "    if normalize:\n",
        "        norm_words = [_normalize_token(w) for w in words]\n",
        "    else:\n",
        "        norm_words = words\n",
        "\n",
        "    cleaned: List[str] = []\n",
        "    i = 0\n",
        "    while i < n:\n",
        "        found = False\n",
        "        # largest possible chunk at i that can repeat at least once\n",
        "        max_L = min(max_seq_len, (n - i) // 2)\n",
        "        # try long -> short so we prefer whole-sentence matches\n",
        "        for L in range(max_L, 0, -1):\n",
        "            a_norm = norm_words[i:i+L]\n",
        "            b_norm = norm_words[i+L:i+2*L]\n",
        "            if a_norm == b_norm:\n",
        "                # count how many consecutive copies of this chunk exist\n",
        "                count = 1\n",
        "                while i + (count+1)*L <= n and norm_words[i + count*L : i + (count+1)*L] == a_norm:\n",
        "                    count += 1\n",
        "                # keep ONE copy (the original tokens, not normalized)\n",
        "                cleaned.extend(words[i:i+L])\n",
        "                # skip all copies\n",
        "                i += count * L\n",
        "                found = True\n",
        "                break\n",
        "        if not found:\n",
        "            # no repeated chunk starting at i -> keep single token\n",
        "            cleaned.append(words[i])\n",
        "            i += 1\n",
        "\n",
        "    return str(cleaned)\n",
        "\n",
        "long_text = remove_consecutive_duplicate_phrases(text)  # your video transcript\n",
        "\n",
        "# Wrap text to 80 characters per line\n",
        "joined_text = ''\n",
        "for word in long_text:\n",
        "  joined_text += word\n",
        "\n",
        "replace = ['\"',\"'\",\",\"]\n",
        "for punc in replace:\n",
        "  joined_text = joined_text.replace(punc,\"\")\n",
        "new_text = joined_text.strip(\"[]\")\n",
        "lister = new_text.split()\n",
        "newer_text = lister[5:-1]\n",
        "newest_text = \" \".join(newer_text)\n",
        "\n",
        "wrapped_text = textwrap.fill(newest_text, width=110)\n",
        "print(wrapped_text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
